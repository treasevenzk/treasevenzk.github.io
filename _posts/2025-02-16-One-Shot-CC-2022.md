---
layout:     post
title:      One-Shot Tuner 2022
subtitle:   One-Shot Tuner for Deep Learning Compilers
date:       2025-02-16
author:     Treaseven
header-img: img/bg18.jpg
catalog: true
tags:
    - optimizing compilers
    - autotuning
    - performance models
    - deep neural networks
---


### Motivations and Challenges
- 现有的输入数据和代价模型并不是专门设计用于学习task、knob、performance这些参数
- 任务采样的方法决定了代价模型的通用性
- 硬件测量的随机分布导致性能分布偏斜

### Design and Implementation

#### Predictor Model Construction

<img width="1000" height="250" src="../img/post-one-shot-tuner-overview.png"/>

***Prior-Guided Task Sampling(PGS)***

<img width="500" height="600" src="../img/post-one-shot-tuner-dataset-generation.png"/>

***Exploration-Based Code Sampling(EBS)***

<img width="500" height="250" src="../img/post-one-shot-tuner-predictior-model-architecture.png"/>

***Feature Generation***<br>
***Predictor Model Architectured***

#### Optimal Code Generation

### Evaluation

* End-to-End Compilation Time

<img width="1000" height="250" src="../img/post-one-shot-tuner-compilation-time.png"/>

<img width="500" height="250" src="../img/post-one-shot-tuner-breakdown-compilation-time.png"/>

* Inference Time

<img width="1000" height="250" src="../img/post-one-shot-tuner-inference-time.png"/>

* Ablation Analysis

* Comparison with TVM Auto-scheduler



### Reference
[One-Shot Tuner for Deep Learning Compilers](https://dl.acm.org/doi/pdf/10.1145/3497776.3517774)