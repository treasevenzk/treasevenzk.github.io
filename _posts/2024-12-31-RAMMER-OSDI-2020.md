---
layout:     post
title:      RAMMER 2020
subtitle:   RAMMER Enabling Holistic Deep Learning Compiler Optimizations with rTasks
date:       2024-12-31
author:     Treaseven
header-img: img/bg20.jpg
catalog: true
tags:
    - Machine Learning
    - Spatio-temporal Schedule
---

### Motivation
Existing Methods: a two-layered scheduling approach(an inter-operator DFD layer scheduler„ÄÅan intra-operator scheduler)<br>
***Limitions***:<br>
(1) Hardware-managed intra-operator scheduling leads to low GPU utilization

<img width="500" height="300" src="../img/post-rammer-gpu-utilization.png"/>

(2) High inter-operator scheduling overheads

<img width="500" height="250" src="../img/post-rammer-average-kernel-time.png"/>

(3) Interplay between inter- and intra-operator scheduling

<img width="500" height="200" src="../img/post-rammer-illustration.png"/>


### Rammer's Design

<img width="500" height="600" src="../img/post-rammer.png"/>

***rOperator***

<img width="500" height="180" src="../img/post-rammer-execution.png"/>

***Virtualized Parallel Device***

***rTask-aware DFG Compiler***:
(1) Scheduling interfaces
(2) Compile-time profiling
(3) Scheduling policy

<img width="500" height="500" src="../img/post-rammer-algorithm.png"/>


### Evaluation

<img width="1000" height="200" src="../img/post-rammer-performance.png"/>


<img width="500" height="200" src="../img/post-rammer-batch-size.png"/>


<img width="500" height="200" src="../img/post-rammer-larger-input.png"/>


<img width="500" height="200" src="../img/post-rammer-gpu-utilization-comparison.png"/>


<img width="1000" height="200" src="../img/post-rammer-amd.png"/>