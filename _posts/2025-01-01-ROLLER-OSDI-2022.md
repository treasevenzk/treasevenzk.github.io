---
layout:     post
title:      ROLLER OSDI 2022
subtitle:   ROLLER Fast and Efficient Tensor Compilation for Deep Learning
date:       2025-01-01
author:     Treaseven
header-img: img/bg20.jpg
catalog: true
tags:
    - Tensor Compilers
    - Deep Learning
    - Data Processing Pipeline
---

### Contribution
- instead of multi-level nested loops, roller treats the computation in a DNN operator as a data processing pipeline, where data tiles are moved and processed in an abstracted hardware with parallel execution units and multi layer memory hierarchy
- the shape of a data tile should align with the hardware characteristics, including memory bank, memory transaction length, and minimum schedulable unit
- the performance of an aligned pipeline is highly predictable

### Motivation

<img width="500" height="300" src="/img/post-roller-access-pattern.png"/>

### System Design

<img width="500" height="400" src="/img/post-roller.png"/>

#### Tensor Expression and rTile

<img width="500" height="300" src="/img/post-roller-illustration.png"/>

***Alignment with the hardware execution unit***<br>

***Alignment with memory transaction***<br>

***Alignment with memory bank***<br>
现代硬件中的内存通常被分成多个bank，当多个访问请求同时访问一个bank时会产生冲突，导致性能下降，避免bank冲突，提高内存访问的并行度
* 未对齐: 多个访问请求竞争同一个bank，需要串行访问
* 对齐后: 多个访问请求分散到不同bank，可以并行访问

***Alignment with tensor shape***<br>

***Deriving all rTiles***<br>

***Calculating data reuse score***<br>
$S_i = \frac{Q(T) - Q(T^{'}_{i})}{F(T^{'}_{i}) - F(T)}$

#### Tensor Program Construction
***rTile program***
- the computation and memory movement should fully leverage the hardware features
- the throught should saturate the bottleneck stage
- needs to be sufficient parallelism

***Scaling up an rProgram***

<img width="500" height="700" src="/img/post-roller-algorithm.png"/>

***Scaling out an rProgram***

***Small operator and irregular tensor shape***

#### Efficient Evaluation of an rProgram





### Evaluation

<img width="1000" height="500" src="/img/post-roller-operator-performance.png"/>


<img width="500" height="250" src="/img/post-roller-compilation-time.png"/>


<img width="500" height="250" src="/img/post-roller-kernel-time-matmul.png"/>


<img width="500" height="250" src="/img/post-roller-kernel-time-conv.png"/>


<img width="500" height="250" src="/img/post-roller-compilation-time-both.png"/>


### Reference
[ROLLER: Fast and Efficient Tensor Compilation for Deep Learning](https://www.usenix.org/system/files/osdi22-zhu.pdf)