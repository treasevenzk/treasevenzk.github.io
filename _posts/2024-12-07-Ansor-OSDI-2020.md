---
layout:     post
title:      Ansor OSDI 2020
subtitle:   Ansor Generating High-Performance Tensor Programs for Deep Learning
date: Â  Â  Â  2024-12-07
author:     Treaseven
header-img: img/bg15.jpg
catalog: true
tags:	
    - Tensor Programs
    - Deep learning
---

### è¦è§£å†³çš„é—®é¢˜
åœ¨ä¸åŒçš„ç¡¬ä»¶å¹³å°ä¸Šï¼Œè®¾è®¡é«˜æ€§èƒ½tensor programå¯¹äºä¸åŒç®—æ³•ååˆ†å›°éš¾ï¼Œç”±äºç›®å‰æœ‰é™çš„æœç´¢ç©ºé—´å’Œä½æ•ˆçš„æœç´¢ç­–ç•¥

### å·²æœ‰çš„è§£å†³æ–¹æ¡ˆ
1. predefined manually-written templates (TVMã€FlexTensor)
2. aggressive pruning by evaluating incomplete programs (Halide auto-scheduler)

<img width="600" height="200" src="/img/post-ansor-compare.png"/>

å­˜åœ¨çš„é—®é¢˜:<br>
**1. TVM FlexTensor**
éœ€è¦å¤§é‡äººå·¥ç¼–å†™æ¨¡æ¿ã€æœç´¢ç©ºé—´å—é™äºæ‰‹å†™æ¨¡æ¿ã€éš¾ä»¥æ”¯æŒæ–°ç®—å­å’Œç¡¬ä»¶<br>
**2. Halide**
è¯„ä¼°å›°éš¾ã€å†³ç­–é¡ºåºå›ºå®šã€é”™è¯¯ä¼ æ’­


### æ–°çš„è§£å†³æ–¹æ¡ˆ
é¢ä¸´çš„æŒ‘æˆ˜:  
(1) constructing a large search space for a given computation definition-**a hierarchical representation**  
(2) search efficiently-**evolutionary search and a learned cost model**  
(3) recognize and prioritize the subgraphs that are critical to the end-to-end performance (~~å¯¹æ¯ä¸ªå­å›¾è¿›è¡Œä¼˜åŒ–ç»„åˆä¼šå¯¼è‡´æ¬¡ä¼˜æ€§èƒ½?~~)(æœ‰äº›å­å›¾çš„ä¼˜åŒ–å¯¹äºæ€§èƒ½æå‡æ— å¤ªå¤§ä½œç”¨)-**a task scheduler**

### Design


<img width="500" height="400" src="/img/post-ansor.png"/>

#### Program Sampling
(1) **Sketch Generation**
```
# æ­¥éª¤1ï¼š æŒ‰æ‹“æ‰‘åºè®¿é—®DAGä¸­çš„èŠ‚ç‚¹
for node in topological_order(DAG):
    # æ­¥éª¤2ï¼šæ ¹æ®èŠ‚ç‚¹ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
    if is_compute_intensive(node): # è®¡ç®—å¯†é›†å‹èŠ‚ç‚¹(å¦‚conv2d,matmul)
        build_tile_and_fusion_structure(node)
    elif is_element_wise(node): # ç®€å•çš„é€å…ƒç´ æ“ä½œ(å¦‚ReLU,add)
        inline_node(node)
```
***å¤„ç†è§„åˆ™***
```
rule-1 skip ç›´æ¥è·³åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
# ä¾‹å¦‚å¤„ç†ä¸€ä¸ªå¤æ‚çš„å·ç§¯èŠ‚ç‚¹ï¼Œç”±äºå·ç§¯æ“ä½œå¤æ‚ï¼Œä¸èƒ½å†…è”ï¼Œæ‰€ä»¥ç›´æ¥è·³è¿‡
for i, j in range(H, W):
    conv2d[i,j] = complex_computation()
# è·³è¿‡åä¿æŒåŸæ ·ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªèŠ‚ç‚¹

rule-2 always inline
# åŸå§‹ä»£ç 
t1 = relu(x)
t2 = t1 + y
#å†…è”å
t2 = relu(x) + y

rule-3 multi-level tiling å¤šçº§åˆ†å—è§„åˆ™
# åŸå§‹çŸ©é˜µä¹˜æ³•
for i, j, k in range(N, M, K):
    C[i, j] += A[i, k] * B[k, j]
# åº”ç”¨å¤šçº§åˆ†å—å
for i0 in range(N//64):                 # ç©ºé—´å¾ªç¯S
    for j0 in range(M//64):             # ç©ºé—´å¾ªç¯S
        for k0 in range(k//32):         # å½’çº¦å¾ªç¯R
            for i1 in range(64):        # ç©ºé—´å¾ªç¯S
                for k1 in range(32):    # å½’çº¦å¾ªç¯R
                    for j1 in range(64):# ç©ºé—´å¾ªç¯S
                        C[i0*64+i1, j0*64+j1] += A[i0*64+i1, k0*32+k1] * B[k0*32+k1, j0*64+j1]

rule-4 multi-level tiling with fusion
# åŸå§‹ä»£ç 
# 1. çŸ©é˜µä¹˜æ³•
for i, j, k:
    C[i, j] += A[i, k] * B[k, j]
# 2. ReLUæ“ä½œ
for i, j:
    D[i, j] = relu(C[i, j])
#èåˆåçš„ä»£ç 
for i0, j0:
    for i1, j1:
        for k:
            # çŸ©é˜µä¹˜æ³•å’ŒReLUåœ¨åŒä¸€ä¸ªå¾ªç¯å†…å®Œæˆ
            C[i0*64+i1, j0*64+j1] += A[i0*64+i1, k] * B[k, j0*64+j1]
        D[i0*64+i1, j0*64+j1] = relu(C[i0*64+i1, j0*64+j1])

rule-5 add cache stage
# åŸå§‹ä»£ç 
for i, j, k:
    C[i, j] += A[i, k] * B[k, j]
# æ·»åŠ ç¼“å­˜å
# 1. è®¡ç®—å¹¶å†™å…¥ç¼“å­˜
for i0, j0:
    cache[i0, j0] = compute_block(A, B, i0, j0)
# 2. ä»ç¼“å­˜å†™å›å†…å­˜
for i0, j0:
    C[i0:i0+block, j0:j0+block] = cache[i0, j0]

rule-6 reduction factorization
# åŸå§‹ä»£ç  - è®¡ç®—çŸ©é˜µæ¯åˆ—çš„å’Œ
for j in range(N):
    for i in range(M):
        sum[j] += matrix[i, j]
# åˆ†è§£å - å¼•å…¥ä¸­é—´ç»“æœå®ç°å¹¶è¡Œ
# 1. å¹¶è¡Œè®¡ç®—éƒ¨åˆ†å’Œ
parallel for b in range(B):
    for j in range(N):
        for i in range(b*M//B, (b+1)*M//B):
            partial_sum[b, j] += matrix[i, j]
# 2. å½’çº¦éƒ¨åˆ†å’Œå¾—åˆ°æœ€ç»ˆç»“æœ
for j in range(N):
    for b in range(B):
        sum[j] += partial_sum[b, j]
```
***Example***
<img width="1000" height="800" src="/img/post-ansor-example.png"/>


### Evaulation
Single operator ğŸ‘‰ Subgraph ğŸ‘‰ End-to-end network
<img width="500" height="300" src="/img/post-ansor-operator.png"/>


<img width="500" height="300" src="/img/post-ansor-operator-ablation.png"/>



<img width="500" height="400" src="/img/post-ansor-subgraph.png"/>



<img width="500" height="900" src="/img/post-ansor-network.png"/>



<img width="500" height="900" src="/img/post-ansor-network.png"/>




<img width="500" height="300" src="/img/post-ansor-network-ablation.png"/>

#### search time

<img width="500" height="300" src="/img/post-ansor-time.png"/>


#### æ€è€ƒ


#### å‚è€ƒæ–‡çŒ®

[Ansor: Generating High-Performance Tensor Programs for Deep Learning](https://www.usenix.org/system/files/osdi20-zheng.pdf)
