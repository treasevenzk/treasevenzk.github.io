---
layout:     post
title:      Pytorch Tutorial
subtitle:   Pytorch
date:       2024-12-26
author:     Treaseven
header-img: img/bg18.jpg
catalog: true
tags:
    - Pytorch
---

```
torch.nn
class torch.nn.Parameter() requires_grad默认为True,在BP的过程中会对其求微分

卷积层
class torch.nn.Conv(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)
池化层
class torch.nn.MaxPool(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
激活层
class torch.nn.ReLU(inplace=False)
标准化层
class torch.nn.BatchNorm(num_features, eps=1e-05, momentum=0.1, affine=True)
线性层
class torch.nn.Linear(in_features, out_features, bias=True)
dropout层
class torch.nn.Dropout(p=0.5, inplace=False)


torch.optim
class torch.optim.Optimizer(params, defaults)
class torch.optim.Adadelta(params, lr=1.0, rho=0.9, eps=1e-06, weight_decay=0)
class torch.optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0)
class torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_deacy=0)
class torch.optim.SGD(params, lr=0.01, mementum=0, dampening=0, weight_decay=0, nesterov=False)

torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1) 用于在训练过程中阶梯式地降低学习率
nn.utils.clip_grad_norm_ 梯度裁剪，用于防止梯度爆炸问题
```

```
torch.repeat_interleave(input, repeats, dim=None): 用于重复张量的元素
torch.scatter_add(input, dim, index, src): 用于按索引累加值到目标张量中，用于构建稀疏操作
torch.randperm: 用于生成随机排列的函数，返回一个包含从0到n-1的整数的随机排列张量
torch.arrange: 用于生成等差数列张量的函数
torch.cumsum: 沿着指定维度计算张量元素的累积求和
```

PAMDataLoader(tmp_set, self.infer_batch_size, self.device, self.use_workload_embedding, fea_norm_vec, fea_norm_vec_buf)

Pytorch 架构图
torch.nn 神经网络
torch.optim 优化器
torch.utils 工具函数
torch 核心 张量计算
torch.autograd 自动微分
torch.utils.data 数据加载

自动求导: 1.训练神经网络时计算梯度 2. 进行反向传播算法的实现

创建张量
torch.tensor(data): 从Python列表或numpy数组创建张量 x = torch.tensor([[1, 2], [3, 4]])
torch.zeros(size): 创建一个全为零的张量
torch.ones(size): 创建一个全为1的张量
torch.empty(size): 创建一个未初始化的张量
torch.rand(size): 创建一个服从均匀分布的随机张量，值在[0, 1)
torch.randn(size): 创建一个服从正态分布的随机张量，均值为0，标准差为1
torch.arrange(start, end, step): 创建一个一维序列张量，类似于Python的range
torch.linspace(start, end, steps): 创建一个在指定范围内等间隔的序列张量
torch.eye(size): 创建一个单位矩阵，对角线为1，其他为0
torch.from_numpy(ndarray): 将numpy数组转换为张量

张量的属性
.shape: 获取张量的形状
.size(): 获取张量的形状
.dtype: 获取张量的数据类型
.device: 查看张量所在的设备(CPU/GPU)
.dim(): 获取张量的维度数
.requires_grad: 是否启用梯度计算
.numel(): 获取张量中的元素总数
.is_cuda: 检查张量是否在GPU上
.T: 获取张量的转置
.item(): 获取单元素张量的值
.is_continguous(): 检查张量是否连续存储

张量的操作
+ - * / 元素级加、减、乘、除
torch.matmul(x, y) 矩阵乘法
torch.dot(x, y) 向量点积
torch.sum(x): 求和
torch.mean(x): 求平均值
torch.max(x): 求最大值
torch.min(x): 求最小值
torch.argmax(x, dim): 返回最大值的索引(指定维度)
torch.softmax(x, dim): 计算softmax(指定维度)
x.view(shape): 改变张量的形状(不改变数据)
x.reshape(shape): 类似于view,但更灵活
x.t(): 转置矩阵
x.unsqueeze(dim): 在指定维度添加一个维度
x.squeeeze(dim): 去掉指定维度为1的维度
torch.cat((x, y), dim): 按指定维度连接多个张量

张量的GPU加速
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
x = torch.tensor([1.0, 2.0, 3.0], device=device)
torch.cuda.is_available()

张量与numpy互操作
torch.from_numpy(ndarray): 将numpy数组转换为张量
x.numpy(): 将张量转换为numpy数组

神经网络(nn.Module)
在pytorch中，构建神经网络通常需要继承nn.Module类
nn.Module是所有神经网络模块的基类，需定义以下两个部分:
__init__(): 定义网络层
forward(): 定义数据的前向传播过程

nn.Linear(in_features, out_features): 全连接层，输入in_features个特征，输出out_features个特征
nn.Conv2d(in_channels, out_channels, kernel_size)
nn.MaxPool2d(kernel_size)
nn.ReLU()
nn.Softmax(dimx)

激活函数
torch.sigmoid: 用于二分类问题，输出值在0和1之间
torch.tanh: 输出值在-1和1之间，常用于输出层之间
torch.nn.functional.relu: 定义为f(x) = max(0, x)，解决梯度消失问题
softmax: 用于多分类问题的输出层，将输出转换为概率分布

损失函数
nn.MSELoss(): 均方误差
nn.CrossEntropyLoss(): 交叉熵损失,计算输出和真实标签之间的交叉熵
nn.BCEWithLogitsLoss(): 二分类问题，结合sigmoid激活和二元交叉熵损失

优化器: 负责在训练过程中更新网络的权重和偏置
torch.optim.SGD(model.parameters(), lr=0.01)
torch.optim.Adam(model.parameters(), lr=0.001)

Pytorch 数据处理与加载
torch.utils.data.Dataset: 抽象类，允许从自己的数据源中创建数据集，需继承并实现以下两个方法
__len__(self): 返回数据集中的样本数量
__getitem__(self, idx): 通过索引返回一个样本

使用DataLoader加载数据: 用于从Dataset中按批次加载数据
torch.utils.data.DataLoader

预处理与数据增强
transforms.Compose(): 将多个变换操作组合在一起
transforms.Resize(): 调整图像大小
transforms.ToTensor(): 将图像转换为Pytorch张量，值会被归一化到[0, 1]范围
transforms.Normalize(): 标准化图像数据，通常使用预训练模型时需要进行标准化处理
