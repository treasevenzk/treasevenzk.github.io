---
layout:     post
title:      XTAT 2021
subtitle:   A Flexible Approach to Autotuning Multi-Pass Machine Learning Compilers
date:       2025-02-17
author:     Treaseven
header-img: img/bg18.jpg
catalog: true
tags:
    - compilers
    - autotuning
    - machine learning
---

### Motivation
- 子图划分不仅复杂同时会限制优化的范围
- 之前的搜索专注于编译流中的单一阶段，不适合大多数深度学习编译器的多层架构

### XTAT-M
<img width="500" height="1000" src="../img/post-xtat-formulation.png"/>

### XTAT
#### XTAT's Optimization-Specific Search Formulations
- Layout Assignment
- Operator Fusion
- Tile-Size Selection
- Lowering Flags


### Evaluation

<img width="1000" height="400" src="../img/post-xtat-speedup.png"/>


<img width="500" height="700" src="../img/post-xtat-autotuning.png"/>


<img width="500" height="350" src="../img/post-xtat-layout-autotuning.png"/>


<img width="500" height="400" src="../img/post-xtat-fusion-autotuning.png"/>


<img width="500" height="400" src="../img/post-xtat-joint-autotuning.png"/>


### Reference
[A Flexible Approach to Autotuning Multi-Pass Machine Learning Compilers](https://mangpo.net/papers/xla-autotuning-pact2021.pdf)